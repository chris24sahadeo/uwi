{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees  \n",
    "\n",
    "## [Dr Kieu's Classification Lecture Notes](http://120.108.116.237/~ktduc/DA/Lecs/Topic01%20Classification%20Basics%20Jiawei%20Han.pdf) \n",
    "(slides 10 to 43) for indepth explanations on the theory behind Decision Trees and Attribute Selection Methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Inducing Decision Trees with [`sklearn.tree.DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Imports\n",
    "- We use `numpy` for its arrays\n",
    "- `pandas` for dataframes and easy handling of `.csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from `diabetes.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "5              5      116             74              0        0  25.6   \n",
      "6              3       78             50             32       88  31.0   \n",
      "7             10      115              0              0        0  35.3   \n",
      "8              2      197             70             45      543  30.5   \n",
      "9              8      125             96              0        0   0.0   \n",
      "10             4      110             92              0        0  37.6   \n",
      "11            10      168             74              0        0  38.0   \n",
      "12            10      139             80              0        0  27.1   \n",
      "13             1      189             60             23      846  30.1   \n",
      "14             5      166             72             19      175  25.8   \n",
      "15             7      100              0              0        0  30.0   \n",
      "16             0      118             84             47      230  45.8   \n",
      "17             7      107             74              0        0  29.6   \n",
      "18             1      103             30             38       83  43.3   \n",
      "19             1      115             70             30       96  34.6   \n",
      "20             3      126             88             41      235  39.3   \n",
      "21             8       99             84              0        0  35.4   \n",
      "22             7      196             90              0        0  39.8   \n",
      "23             9      119             80             35        0  29.0   \n",
      "24            11      143             94             33      146  36.6   \n",
      "25            10      125             70             26      115  31.1   \n",
      "26             7      147             76              0        0  39.4   \n",
      "27             1       97             66             15      140  23.2   \n",
      "28            13      145             82             19      110  22.2   \n",
      "29             5      117             92              0        0  34.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "738            2       99             60             17      160  36.6   \n",
      "739            1      102             74              0        0  39.5   \n",
      "740           11      120             80             37      150  42.3   \n",
      "741            3      102             44             20       94  30.8   \n",
      "742            1      109             58             18      116  28.5   \n",
      "743            9      140             94              0        0  32.7   \n",
      "744           13      153             88             37      140  40.6   \n",
      "745           12      100             84             33      105  30.0   \n",
      "746            1      147             94             41        0  49.3   \n",
      "747            1       81             74             41       57  46.3   \n",
      "748            3      187             70             22      200  36.4   \n",
      "749            6      162             62              0        0  24.3   \n",
      "750            4      136             70              0        0  31.2   \n",
      "751            1      121             78             39       74  39.0   \n",
      "752            3      108             62             24        0  26.0   \n",
      "753            0      181             88             44      510  43.3   \n",
      "754            8      154             78             32        0  32.4   \n",
      "755            1      128             88             39      110  36.5   \n",
      "756            7      137             90             41        0  32.0   \n",
      "757            0      123             72              0        0  36.3   \n",
      "758            1      106             76              0        0  37.5   \n",
      "759            6      190             92              0        0  35.5   \n",
      "760            2       88             58             26       16  28.4   \n",
      "761            9      170             74             31        0  44.0   \n",
      "762            9       89             62              0        0  22.5   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.627   50        1  \n",
      "1                       0.351   31        0  \n",
      "2                       0.672   32        1  \n",
      "3                       0.167   21        0  \n",
      "4                       2.288   33        1  \n",
      "5                       0.201   30        0  \n",
      "6                       0.248   26        1  \n",
      "7                       0.134   29        0  \n",
      "8                       0.158   53        1  \n",
      "9                       0.232   54        1  \n",
      "10                      0.191   30        0  \n",
      "11                      0.537   34        1  \n",
      "12                      1.441   57        0  \n",
      "13                      0.398   59        1  \n",
      "14                      0.587   51        1  \n",
      "15                      0.484   32        1  \n",
      "16                      0.551   31        1  \n",
      "17                      0.254   31        1  \n",
      "18                      0.183   33        0  \n",
      "19                      0.529   32        1  \n",
      "20                      0.704   27        0  \n",
      "21                      0.388   50        0  \n",
      "22                      0.451   41        1  \n",
      "23                      0.263   29        1  \n",
      "24                      0.254   51        1  \n",
      "25                      0.205   41        1  \n",
      "26                      0.257   43        1  \n",
      "27                      0.487   22        0  \n",
      "28                      0.245   57        0  \n",
      "29                      0.337   38        0  \n",
      "..                        ...  ...      ...  \n",
      "738                     0.453   21        0  \n",
      "739                     0.293   42        1  \n",
      "740                     0.785   48        1  \n",
      "741                     0.400   26        0  \n",
      "742                     0.219   22        0  \n",
      "743                     0.734   45        1  \n",
      "744                     1.174   39        0  \n",
      "745                     0.488   46        0  \n",
      "746                     0.358   27        1  \n",
      "747                     1.096   32        0  \n",
      "748                     0.408   36        1  \n",
      "749                     0.178   50        1  \n",
      "750                     1.182   22        1  \n",
      "751                     0.261   28        0  \n",
      "752                     0.223   25        0  \n",
      "753                     0.222   26        1  \n",
      "754                     0.443   45        1  \n",
      "755                     1.057   37        1  \n",
      "756                     0.391   39        0  \n",
      "757                     0.258   52        1  \n",
      "758                     0.197   26        0  \n",
      "759                     0.278   66        1  \n",
      "760                     0.766   22        0  \n",
      "761                     0.403   43        1  \n",
      "762                     0.142   33        0  \n",
      "763                     0.171   63        0  \n",
      "764                     0.340   27        0  \n",
      "765                     0.245   30        0  \n",
      "766                     0.349   47        1  \n",
      "767                     0.315   23        0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`data.loc`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.loc.html) Access a group of rows and columns by label(s) or a boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "5              5      116             74              0        0  25.6   \n",
      "6              3       78             50             32       88  31.0   \n",
      "7             10      115              0              0        0  35.3   \n",
      "8              2      197             70             45      543  30.5   \n",
      "9              8      125             96              0        0   0.0   \n",
      "10             4      110             92              0        0  37.6   \n",
      "11            10      168             74              0        0  38.0   \n",
      "12            10      139             80              0        0  27.1   \n",
      "13             1      189             60             23      846  30.1   \n",
      "14             5      166             72             19      175  25.8   \n",
      "15             7      100              0              0        0  30.0   \n",
      "16             0      118             84             47      230  45.8   \n",
      "17             7      107             74              0        0  29.6   \n",
      "18             1      103             30             38       83  43.3   \n",
      "19             1      115             70             30       96  34.6   \n",
      "20             3      126             88             41      235  39.3   \n",
      "21             8       99             84              0        0  35.4   \n",
      "22             7      196             90              0        0  39.8   \n",
      "23             9      119             80             35        0  29.0   \n",
      "24            11      143             94             33      146  36.6   \n",
      "25            10      125             70             26      115  31.1   \n",
      "26             7      147             76              0        0  39.4   \n",
      "27             1       97             66             15      140  23.2   \n",
      "28            13      145             82             19      110  22.2   \n",
      "29             5      117             92              0        0  34.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "738            2       99             60             17      160  36.6   \n",
      "739            1      102             74              0        0  39.5   \n",
      "740           11      120             80             37      150  42.3   \n",
      "741            3      102             44             20       94  30.8   \n",
      "742            1      109             58             18      116  28.5   \n",
      "743            9      140             94              0        0  32.7   \n",
      "744           13      153             88             37      140  40.6   \n",
      "745           12      100             84             33      105  30.0   \n",
      "746            1      147             94             41        0  49.3   \n",
      "747            1       81             74             41       57  46.3   \n",
      "748            3      187             70             22      200  36.4   \n",
      "749            6      162             62              0        0  24.3   \n",
      "750            4      136             70              0        0  31.2   \n",
      "751            1      121             78             39       74  39.0   \n",
      "752            3      108             62             24        0  26.0   \n",
      "753            0      181             88             44      510  43.3   \n",
      "754            8      154             78             32        0  32.4   \n",
      "755            1      128             88             39      110  36.5   \n",
      "756            7      137             90             41        0  32.0   \n",
      "757            0      123             72              0        0  36.3   \n",
      "758            1      106             76              0        0  37.5   \n",
      "759            6      190             92              0        0  35.5   \n",
      "760            2       88             58             26       16  28.4   \n",
      "761            9      170             74             31        0  44.0   \n",
      "762            9       89             62              0        0  22.5   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  \n",
      "0                       0.627   50  \n",
      "1                       0.351   31  \n",
      "2                       0.672   32  \n",
      "3                       0.167   21  \n",
      "4                       2.288   33  \n",
      "5                       0.201   30  \n",
      "6                       0.248   26  \n",
      "7                       0.134   29  \n",
      "8                       0.158   53  \n",
      "9                       0.232   54  \n",
      "10                      0.191   30  \n",
      "11                      0.537   34  \n",
      "12                      1.441   57  \n",
      "13                      0.398   59  \n",
      "14                      0.587   51  \n",
      "15                      0.484   32  \n",
      "16                      0.551   31  \n",
      "17                      0.254   31  \n",
      "18                      0.183   33  \n",
      "19                      0.529   32  \n",
      "20                      0.704   27  \n",
      "21                      0.388   50  \n",
      "22                      0.451   41  \n",
      "23                      0.263   29  \n",
      "24                      0.254   51  \n",
      "25                      0.205   41  \n",
      "26                      0.257   43  \n",
      "27                      0.487   22  \n",
      "28                      0.245   57  \n",
      "29                      0.337   38  \n",
      "..                        ...  ...  \n",
      "738                     0.453   21  \n",
      "739                     0.293   42  \n",
      "740                     0.785   48  \n",
      "741                     0.400   26  \n",
      "742                     0.219   22  \n",
      "743                     0.734   45  \n",
      "744                     1.174   39  \n",
      "745                     0.488   46  \n",
      "746                     0.358   27  \n",
      "747                     1.096   32  \n",
      "748                     0.408   36  \n",
      "749                     0.178   50  \n",
      "750                     1.182   22  \n",
      "751                     0.261   28  \n",
      "752                     0.223   25  \n",
      "753                     0.222   26  \n",
      "754                     0.443   45  \n",
      "755                     1.057   37  \n",
      "756                     0.391   39  \n",
      "757                     0.258   52  \n",
      "758                     0.197   26  \n",
      "759                     0.278   66  \n",
      "760                     0.766   22  \n",
      "761                     0.403   43  \n",
      "762                     0.142   33  \n",
      "763                     0.171   63  \n",
      "764                     0.340   27  \n",
      "765                     0.245   30  \n",
      "766                     0.349   47  \n",
      "767                     0.315   23  \n",
      "\n",
      "[768 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "inputs = data.loc[:, :'Age']   # returns all rows, and all columns up to and including Age\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "5      0\n",
      "6      1\n",
      "7      0\n",
      "8      1\n",
      "9      1\n",
      "10     0\n",
      "11     1\n",
      "12     0\n",
      "13     1\n",
      "14     1\n",
      "15     1\n",
      "16     1\n",
      "17     1\n",
      "18     0\n",
      "19     1\n",
      "20     0\n",
      "21     0\n",
      "22     1\n",
      "23     1\n",
      "24     1\n",
      "25     1\n",
      "26     1\n",
      "27     0\n",
      "28     0\n",
      "29     0\n",
      "      ..\n",
      "738    0\n",
      "739    1\n",
      "740    1\n",
      "741    0\n",
      "742    0\n",
      "743    1\n",
      "744    0\n",
      "745    0\n",
      "746    1\n",
      "747    0\n",
      "748    1\n",
      "749    1\n",
      "750    1\n",
      "751    0\n",
      "752    0\n",
      "753    1\n",
      "754    1\n",
      "755    1\n",
      "756    0\n",
      "757    1\n",
      "758    0\n",
      "759    1\n",
      "760    0\n",
      "761    1\n",
      "762    0\n",
      "763    0\n",
      "764    0\n",
      "765    0\n",
      "766    1\n",
      "767    0\n",
      "Name: Outcome, Length: 768, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target = data['Outcome']       # returns all rows with values in the outcome column\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making training and test data with [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "- `X` is the dataset minus the class label attribute\n",
    "- `Y` is the class label attribute\n",
    "- `train_test_split(X, y)` randomly splits the dataset into 75% training data and 25% testing data:\n",
    "    - `x_train` training data minus class label attribute\n",
    "    - `x_test` testing data minus class label attribute\n",
    "    - `y_train` training data class label attributes\n",
    "    - `y_test` testing data class label attributes\n",
    "\n",
    "The testing data is compaired later on with `y_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = inputs.values\n",
    "y = target.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing [`sklearn.tree.DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "We **train** the model `dt` with `x_train` and `y_train`.  \n",
    "Recall that Decision Trees are an example of **supervised learning**, so we need to know the class label attribute `y_train` during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()  #instance of classifier (model) object\n",
    "dt.fit(x_train, y_train)       #training the model (classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick Prediction and Accuracy Test\n",
    "[**`confusion_matrix`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)  \n",
    "By definition a confusion matrix $C$ is such that $C_{i,j}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\n",
    "\n",
    "Thus in binary classification, the count of true negatives is $C_{0,0}$, false negatives is $C_{1,0}$, true positives is $C_{1,1}$ and false positives is $C_{0,1}$.\n",
    "\\begin{bmatrix}\n",
    "    TN & FP \\\\\n",
    "    FN & TP \\\\\n",
    "\\end{bmatrix}  \n",
    "  \n",
    "  \n",
    "[**`accuracy_score`**](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "\\begin{equation}\n",
    "    \\frac{TP+TN}{P+N}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[101  27]\n",
      " [ 28  36]]\n",
      "\n",
      "A quick accuracy test: \n",
      "0.7135416666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred = dt.predict(x_test) #predicts using the 25% remaining test data  \n",
    "\n",
    "print('Confusion Matrix: \\n{}\\n'.format(confusion_matrix(y_test, y_pred)))\n",
    "print('A quick accuracy test: \\n{}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rapid accuracy tesing with [`sklearn.model_selection.KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "`KFold` makes multiple train, test data splits (in this case $k=5$) for quick accuracy testing on **multiple models**.  \n",
    "  \n",
    "  \n",
    "**NOTE:** `KFold` returns lists of indicies that refer to the dataset, whereas `train_test_split` returns copies of the actual data from the set.  \n",
    "  \n",
    "  \n",
    "\n",
    "- `get_n_splits([X, y, groups])`\tReturns the number of splitting iterations in the cross-validator  \n",
    "- `split(X[, y, groups])`\tGenerate `np.array` of indices to split data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splitting iterations: 5\n",
      "\n",
      "The mean accuracy is 0.7019692725575079\n",
      "[0.6688311688311688, 0.5974025974025974, 0.7272727272727273, 0.7843137254901961, 0.7320261437908496]\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=5)\n",
    "\n",
    "k = k_fold.get_n_splits(X)   # not actually necessary!\n",
    "print('Number of splitting iterations: {}\\n'.format(k))\n",
    "\n",
    "accuracies = []\n",
    "dt2 = DecisionTreeClassifier()\n",
    "for train_idx, test_idx in k_fold.split(X):\n",
    "    train_X, test_X = X[train_idx], X[test_idx]\n",
    "    train_y, test_y = y[train_idx], y[test_idx]\n",
    "    dt2.fit(train_X, train_y)\n",
    "    predictions = dt2.predict(test_X)\n",
    "    accuracy = accuracy_score(test_y, predictions)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print('The mean accuracy is {}'.format(np.mean(accuracies)))\n",
    "print(accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
